Data Profiling steps for the NOAA Weather data:
1. Checked for missing and syntactically wrong data in the raw data fields
2. Identified the missing value codes 9999 or 99999
3. Standardized and checked for irregularities of the Date variable
4. Checked for duplicates within the raw data fields

Data Profiling steps for Divvy Bike data:
1. Checked for missing start_station_id's
2. Verified that the trips column could be changed to numeric
3. Checked for semantically incorrect trip values
4. Made sure hour variable could be converted to datetime
5. Checked for duplicates within the raw data fields

Data Cleaning steps for the NOAA Weather data:
1. Imports raw data CSV file from the data directory
2. Checks raw data for missing values or NOAA's missing value code
3. For temperature, the script extracts the first four digits and rounds to the tenth place in degrees Celsius
4. For wind speed, the script converts the wind speed into meters per second and replaces commas with periods for conversion to floats.
5. For precipitation, the script takes in the accumaltion of all rain water into one hour and converts it into milimeters
6. The cleaning script also takes the Date variable and converts it into pandas datetime variable, and floors the minutes so that the hours are uniform.
7. The script get's rid of exact duplicate hours samples, and converts all missing data into numpy's NaN
8. Finally, the script only keeps the variables hour, temp, wind speed, and precipation and saves it as a CSV. 

Data Cleaning steps for the Divvy Bike data:
1. Checks for missing start_station_id's and ensures the datatype is a string
2. Makes sure hour is a numpy datetime and trips is numeric
3. Removes rows where trips is missing
4. Sorts rows by station_id and hour, and converts this cleaned dataframe to a CSV
