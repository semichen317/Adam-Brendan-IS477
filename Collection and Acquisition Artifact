We used two datasets for our project:
The Divvy bike data was acquired from the Divvy public dataset from this URL, "https://divvy-tripdata.s3.amazonaws.com". The data collected was monthly trip files from May 2024 to May 2025, inclusive.
The NOAA weather data was acquired from the Global Hourly Dataset from this URL, "https://www.ncei.noaa.gov/data/global-hourly/access". The data collected was hourly weather data from the chicago weather station from May 2024 to May 2025, inclusive.

Brief Summary of Scripts:
NOAA prepare script - The NOAA script requests the data from the URL using the requests library in Python. The script then grabs the correct features from the data from the years we wanted to use for our research question. The script also verifies the checksums to assure data integrity. Finally, the script sends the data into CSV files. Two CSV files contain the 2024 and 2025 data seperately, and another CSV file has all the NOAA data ready to be cleaned.
Divvy prepare script - The Divvy script requests the data from the URL using the requests library in Python. The script then grbas the correct features from the monthly zip files. The script also verifies the checksums to ensure data integrity. Finally, the script aggregates all of the zip files into one CSV file to be ready to be cleaned. 

Filesystem
\data
    \interim
            "Contains the interim csvs used for cleaning and the intgrated dataset used before analysis"
    \raw
        \divvy
              "Contains Divvy Zip files"
        \divvy_csv
              "Contains the Divvy CSV files"
        \noaa
              "Contains the NOAA CSV files"
    \cleaned
            "Contains the cleaned CSV files"
\scripts
       \prepare
               "Contains the data acquisition steps for NOAA and Divvy data"
        \cleaned
                "Contains the cleaned scripts for NOAA and Divvy data"
        \integrated
                  "Contains the script to integrate the datasets
        \analysis
                "Contains the analysis script"
\figures
       "Contains visualizations and integration schema"

Filesystem structure and naming convention:
Our filesystem naming system and structure was based off of three things: Data, Scripts, and any Figures we used. 
The data was split based on what stage the data was in, and the naming system was based on the stage of the data and what dataset the data came from.
The Scripts filesystem and naming convention was based off of the stage of the scripts and what data they were transforming.
Finally, the figures dataset has our intergration schema and visualizations

Steps for someone else to acquire data
1. Clone our github repository
2. Create our data directory
3. Run the prepare scripts to acquire the data
4. Verify the Checksums match

Redistribution of data:
Divvy Bike data is shared under an open data license. This means we can redistribute processed data, but not raw data. Other than that, we can download, copy, re-use, redistribute work on the dataset.
NOAA weather data is shared under public domain. This means we can redistribute raw data and use it for any purpose.
